<!-- navbar -->
<nav id="mainNav" class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top">
  <a class="navbar-brand" href="/#page-top">mg-space</a>
  <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarColor02" aria-controls="navbarColor02" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  <div class="collapse navbar-collapse navbar-right" id="navbarColor02">
    <ul class="nav navbar-nav ml-auto">
      <li class="nav-item">
        <a class="nav-link" href="/">Home</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="/bio">Bio</a>
      </li>
      <li class="nav-item active">
        <a class="nav-link" href="/projects">Projects</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="/interests">Interests</a>
      </li>
    </ul>
    <!-- <form class="form-inline my-2 my-lg-0">
      <input class="form-control mr-sm-2" placeholder="Search" type="text">
      <button class="btn btn-secondary my-2 my-sm-0" type="submit">Search</button>
    </form> -->
  </div>
</nav>

<section class="content-section">
  <header>
    <div class="container">
      <h1>projects<span id="underscore">_</span></h1>
      <h6 class="subtitle" style="padding-bottom: 1.5em;">click on the chevrons to expand project details.</h6>

      <!-- <a href="#dignatCollapse" > -->
        <div class="title-bar">
            <h4 style="padding-bottom: 0px; margin-bottom: 0px;">
              <a class="arrow_expander collapsed_arrow btn" data-toggle="collapse" href="#workplacebiasCollapse" role="button" aria-expanded="false" aria-controls="workplacebiasCollapse"><img src="images/down_arrow.svg" class="svg" class="svg"></a>
              <!-- <a class="title_expander title_collapsed" data-toggle="collapse" href="#workplacebiasCollapse" aria-expanded="false" role="button" aria-controls="workplacebiasCollapse"> -->
                Addressing Workplace Bias
              <!-- </a> -->
            </h4>
            <h6 class="subtitle subtitle-break">meeting audio analysis system (Python)</h6>
        </div>
      <!-- </a> -->

      <div class="collapse" id="workplacebiasCollapse">
        <div class="card card-body">
          <p>
            This project originated as part of the Intern Idea Innovation Challenge at MIT Linoln Laboratory during my summer internship there over the summer of 2018. I worked on a team with <a href="https://www.stephaniecarnell.com/">Stevie Carnell</a>, <a href="https://www.linkedin.com/in/toby-macaluso/">Toby Macaluso</a>, <a href="https://www.linkedin.com/in/davidgundana/">David Gundana</a>, and <a href="https://www.linkedin.com/in/robert-hakulin/">Robert Hakulin</a> to develop the idea and present it to five of the Lab's executives. We won the challenge, and I have been able to work on it with <a href="https://www.linkedin.com/in/saucedord/">Ricardo Saucedo</a> and <a href="https://www.linkedin.com/in/hayden-clarke/">Hayden Clarke</a> for our Senior Capstone project at <a href="http://www.cs.slu.edu/">Saint Louis University</a>.
            <br>
            <br>
            Implicit gender bias is unfortunately prominent in the workplace: 42% of women have experienced discrimination at their jobs because of their gender. While this bias can manifest in a variety of ways, a number of meeting-related bias behaviors have been identified: women are more likely to be interrupted by men and talk less frequently and for shorter periods than men. These trends in meeting communication should be particularly concerning for companies, given that the average organization spends 15% of their collective time in meetings. To mitigate these meeting trends, we propose a meeting analysis tool that serves as a bias intervention for individual meeting attendees and a company-wide meter for workplace culture.
            <br>
            <br>
            The system we are implementing records meeting audio and uses speaker diarization technology to differentiate among individuals speaking. We have begun using <a href="https://github.com/tyiannak/pyAudioAnalysis">pyAudioAnalysis</a> for this task and are modifying its source code to meet our needs. <a href="https://github.com/mgottsacker34/pyAudioAnalysis">Here is our forked Github repository</a>. We are in the process of programmatically collecting data on a variety of conversational behaviors, such as speaking times and interruptions. By identifying an individual speaker and when he/she is speaking, we can compile the total speaking time for that meeting attendee. Similarly, overlaps or unusually short gaps between different speakers can be coded as interruptions.
            <br>
            <br>
            The conversational data is then used in two primary visualizations: an individual view and a company-wide view. The individual view will show an attendee his/her own data from previous meetings, such as how long he/she spoke or how many times he/she interrupted other attendees. The individual view could also show historical trend data to demonstrate how his/her behaviors may change over time. By reviewing this information, the attendee should be prompted to and capable of engaging in self-monitoring regarding any biased behaviors he/she may exhibit. The second view is at a company-wide level and will allow companies to review conversational behavior at a larger scale. This view is similar to the individual view but will contain aggregate data from many meeting attendees broken down by various demographics of interest. This information can give upper-level management and Human Resources departments a concrete measure for creating a supportive workplace culture.
          </p>
        </div>
      </div>

      <br>

      <a href="#mitllvizCollapse" >
        <div class="title-bar">
            <h4 style="padding-bottom: 0px; margin-bottom: 0px;">
              <a class="arrow_expander collapsed_arrow btn" data-toggle="collapse" href="#mitllvizCollapse" role="button" aria-expanded="false" aria-controls="mitllvizCollapse"><img src="images/down_arrow.svg" class="svg" class="svg"></a>
              <!-- <a class="title_expander title_collapsed" data-toggle="collapse" href="#mitllvizCollapse" aria-expanded="false" role="button" aria-controls="mitllvizCollapse"> -->
                Visualizing Network Identifier Bindings
              <!-- </a> -->
            </h4>
            <h6 class="subtitle subtitle-break">web-based visualization tool (D3.js)</h6>
        </div>
      <!-- </a> -->

      <div class="collapse" id="mitllvizCollapse">
        <div class="card card-body">
          <p>
            During the Summer of 2018, I worked as a Research Intern in the <a href="https://www.ll.mit.edu/r-d/cyber-security-and-information-sciences/cyber-analytics-and-decision-systems">Cyber Analytics and Decision Systems Group</a> at the <a href="https://www.ll.mit.edu/">MIT Lincoln Laboratory</a>. My group researched software-defined networking (SDN) in the context of cybersecurity systems.
            <br>
            <br>
            SDN allows network analysts to easily deploy access control rules across a network. A novel application for an SDN could leverage this feature to enforce dynamic, role-based policies on high-level information such as usernames at the network level. Such a system requires a database to keep track of the relationships among each device and its respective identifying information on the network. In order to enforce a policy based on a username, the system also needs knowledge of the network device’s hostname, IP address, and MAC address. We refer to the relationships between two network identifiers as bindings.
            <br>
            <br>
            Network-level bindings are inherently dynamic, and bindings between usernames and hostnames complicate the state of the network even more. This dynamic nature makes it difficult for network analysts to validate and debug the policy enforcement system described above. Existing SDN verification tools, such as the web applications bundled with the Floodlight and ONOS controllers display the topology of network devices, but they do not visualize the bindings between network identifiers. Researchers currently test the system by examining database logs. Because of the scale of an enterprise network, this method is inefficient and may lead to change blindness.
            <br>
            <br>
            We approached these issues with a web application displaying two different visual representations of the identifier binding database. Each method shows an overview of the network to allow top-down analysis and features that give users access to the granular data necessary for bottom-up analysis. The first representation is an enriched tabular view, in which the records from the database are fit into a sortable and filterable table. The bindings between each pair of identifiers are encoded as link icons in spaces between each identifier column. The icons are colored along a colorblind-safe gradient. The place on the gradient is calculated based on the current time and the difference between the bindings’ activation and expiration times. This view is intuitive and provides fast searching, but it does not scale perfectly. The second representation displays an undirected graph with the network identifiers as nodes and the bindings as edges between the corresponding identifiers. The edges are colored according to the same gradient as the link icons in the table view. While this view loses some simplicity, it provides a useful visual overview of the network and the analyst can quickly learn whether a certain identifier is bound to several others.
            <br>
            <br>
            We have created a web-based application for the views described above. The tool updates in real-time to ensure the network analyst has up-to-date information. We have not evaluated its efficacy with real users or experts. The next step of our research is to conduct a user study to learn if our application provides insights valuable to the end user. I compiled my summer work into <a href="docs/imc-poster-gottsacker2.pdf">this poster</a>, which I presented at the ACM Internet Measurement Conference in Boston, MA, on October 31, 2018.
          </p>
        </div>
      </div>

      <br>

      <div class="title-bar">
          <h4 style="padding-bottom: 0px; margin-bottom: 0px;">
            <a class="arrow_expander collapsed_arrow btn" data-toggle="collapse" href="#compasslabCollapse" role="button" aria-expanded="false" aria-controls="compasslabCollapse"><img src="images/down_arrow.svg" class="svg" class="svg"></a>
            <!-- <a class="title_expander title_collapsed" data-toggle="collapse" href="#compasslabCollapse" aria-expanded="false" role="button" aria-controls="compasslabCollapse"> -->
              SLU Compass Lab Development
            <!-- </a> -->
          </h4>
          <h6 class="subtitle subtitle-break">web developing and technology consulting</h6>
      </div>

      <div class="collapse" id="compasslabCollapse">
        <div class="card card-body">
          <p>
            I started working with Dr. Nathaniel Rivers at the SLU Computer Assisted Instruction Lab in the Fall of 2018. The mission of the Lab is to connect students and instructors with technologies that can help them produce new media compositions. It was previously abbreviated as the CAI Lab, but we rebranded it as the Compass Lab to more accurately portray the Lab's function. The compass is a technology that helps us navigate through technologically-defined environments.
            <br>
            <div class="col-md-6">
              <a href="https://www.slucompasslab.com">
                <img src="images/compasslab.png" width="100%"/>
              </a>
            </div>
            <br>
            We identified gaps in information distribution from the Lab to its users and kinks in the Lab's internal workflow. For example, there exists a webpage with information about the Lab, but it is difficult to update in a timely manner, and it does not serve a lot of useful content. Additionally, the process to reserve some of the Lab's resources are cumbersome for employees. Dr. Rivers and I determined that designing and implementing a website could address both of these issues.
            <br>
            <br>
            The website displays the Compass Lab's resources in a user-centric and intuitive way. We organize the available technologies primarily according to the functions they serve (i.e., for podcast or video production) while also giving a full catalogue. We provide links to product pages and manuals for more detailed user instructions.
            <br>
            <br>
            Some of the Compass Lab's most important resources are the physical spaces it offers to students and instructors. Its main office has workspaces for editing content and browsing among available technologies. The Lab also has a professionally-equipped recording studio. To connect users with these spaces, I am developing web-based virtual reality tours to orient visitors to their highlights and resources.
            <br>
            <br>
            <a href="https://www.slucompasslab.com">Here is a link to the website.</a>
            <br>
            Look around the frame below to explore the Lab in VR!
            <br>
            <br>
            <iframe style="width: 100%; height: 500px" src="https://compasslab.glitch.me/" frameborder="0">
            </iframe>
          </p>
        </div>
      </div>

      <br>

      <!-- <a href="#dignatCollapse" > -->
        <div class="title-bar">
            <h4 style="padding-bottom: 0px; margin-bottom: 0px;">
              <a class="arrow_expander collapsed_arrow btn" data-toggle="collapse" href="#dignatCollapse" role="button" aria-expanded="false" aria-controls="dignatCollapse"><img src="images/down_arrow.svg" class="svg"></a>
              <!-- <a class="title_expander title_collapsed" data-toggle="collapse" href="#dignatCollapse" aria-expanded="false" role="button" aria-controls="dignatCollapse"> -->
                Digital Native: Exploring Human Attention
              <!-- </a> -->
            </h4>
            <h6 class="subtitle subtitle-break">website (HTML/CSS + JavaScript + A-Frame)</h6>
        </div>
      <!-- </a> -->

      <div class="collapse" id="dignatCollapse">
        <div class="card card-body">
          <p>
            The <a href="http://digitalnative.space">Digital_Native website</a> is a portfolio for my Senior Seminar course on Rhetoric, Writing, and Technology. Throughout the semester, we studied how attention functions in humans and non-humans. In a series of publications, we pursued questions such as: What is attention? How does it work as a commodity? Is it better understand as a function of environmental factors and actors? How do networks of attention form and operate?
            <br>
            <br>
            The small size of the class allowed us students to tailor our projects according to our interests. I chose to focus on digital attention, so each project implicates the field of Human Computer Interaction (HCI), even if I didn't realize it at the time. The portfolio is located at <a href="http://digitalnative.space">digitalnative.space</a>.
            <br>
            <br>
            My last and most HCI-intensive publication examined how humans attend to entirely digital worlds. I created a <a href="https://digital-calibration.glitch.me">web-based mobile Virtual Reality experience</a> using <a href="https://aframe.io">Mozilla's A-Frame technology</a>. I observed some of my friends using the VR application on their phones in a basic headset. Through this project, I learned that human attention can be affected by VR experiences in serious and complex ways. And we don't understand all of those ways yet.
            <br>
            <br>
            My portfolio required a lot of HTML/CSS and JavaScript coding. I hosted it on Github.io, so I didn't have to take care of the backend stuff. <a href="https://github.com/mgottsacker34/digital_native">Here is the Github repo for my portfolio</a>. Admittedly, the repo has a pretty messy commit history because I found myself prototyping and coding very quickly as I ran into configuration issues while trying to meet deadlines.
          </p>
        </div>
      </div>

      <br>

      <div class="title-bar">
          <h4 style="padding-bottom: 0px; margin-bottom: 0px;">
            <a class="arrow_expander collapsed_arrow btn" data-toggle="collapse" href="#safebotCollapse" role="button" aria-expanded="false" aria-controls="safebotCollapse"><img src="images/down_arrow.svg" class="svg" /></a>
            <!-- <a class="title_expander title_collapsed" data-toggle="collapse" href="#safebotCollapse" aria-expanded="false" role="button" aria-controls="safebotCollapse"> -->
              Safe-Bot
            <!-- </a> -->
          </h4>
          <h6 class="subtitle subtitle-break">Facebook Messenger Chatbot (JavaScript)</h6>
      </div>

      <div class="collapse" id="safebotCollapse">
        <div class="card card-body">
          <p>
            This project is the frontend and (incomplete) backend for a Facebook Messenger chatbot that leverages the <a href="https://noonlight.com/">Noonlight API</a> (previously SafeTrek). Noonlight connects users to emergency services in innovative and user-centric ways. Safe-Bot brings their technology to Facebook Messenger and allows users to easily request police, fire, or emergency medical services through a chat conversation. The Facebook Messenger platform is useful for these situations because it is an always-on application that allows users to share a precise location quickly and without having to think about it. It is also advantageous in events where users under duress need to remain silent.
            <br>
            <br>
            I wrote the chatbot frontend in JavaScript. I wrote the backend using Node.JS on a Heroku server. <a href="https://github.com/mgottsacker34/safe-bot">Here is the Github repo for Safe-Bot</a>. I wrote this application in a rapid development window for Noonlight, so its commit history is messy. I was not familiar with Heroku or writing backend JavaScript in general at the time. The chatbot has limitations in that it does not manage multiple users. To be complete, it needs a secure database to manage user tokens. I plan on working on this part in the future. Let me know if you want to help with this part. I would love to collaborate.
            <br>
            <br>
            Here is a demo video of Safe-Bot.
            <br>
            <br>
            <div class="video-container">
              <iframe width="560" height="315" src="https://www.youtube.com/embed/DzfjQ-qbV94" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </div>
          </p>
        </div>
      </div>

      <br>

      <div class="title-bar">
          <h4 style="padding-bottom: 0px; margin-bottom: 0px;">
            <a class="arrow_expander collapsed_arrow btn" data-toggle="collapse" href="#stlparcelCollapse" role="button" aria-expanded="false" aria-controls="stlparcelCollapse"><img src="images/down_arrow.svg" class="svg" /></a>
            St. Louis Parcel Data Aggregation
          </h4>
          <h6 class="subtitle subtitle-break">Linux command line, Bash scripts</h6>
      </div>

      <div class="collapse" id="stlparcelCollapse">
        <div class="card card-body">
          <p>
            My friend and sociology researcher, Andrew Dermott Smith, is conducting research on land parcels in St. Louis. When he started his research project, there was a less-than-ideal data source for parcel data in the City of St. Louis. For example, the City provides some datasets about land data, but the datasets excluded some of the fields he wanted to study. Additionally, the City hosts a web application that provides complete data for each parcel entry when users search by address or by a unique <code>parcelID</code>. This <code>parcelID</code> field can sometimes be derived from information in the datasets.
            <br>
            <br>
            This project involves a series of Bash commands and scripts that constructs <code>parcelID</code> identifiers from the datasets, queries the City's web application, and downloads the resulting web page. Scripts then process the raw HTML files to extract the desired fields. The final result is a tab-separated file with the <code>parcelID</code> and fields that Andrew wanted to study. This data can help produce maps of the city of St. Louis based on total parcel value and how each parcel is used.
            <br>
            <br>
            <a href="https://github.com/mgottsacker34/stl-parcel-data">Here is the Github repo</a>.
          </p>
        </div>
      </div>

      <br>

      <div class="title-bar">
          <h4 style="padding-bottom: 0px; margin-bottom: 0px;">
            <a class="arrow_expander collapsed_arrow btn" data-toggle="collapse" href="#sluplusCollapse" role="button" aria-expanded="false" aria-controls="sluplusCollapse"><img src="images/down_arrow.svg" class="svg" /></a>
            SLU+: Augmenting Campus
          </h4>
          <h6 class="subtitle subtitle-break">Android app (Java, XML)</h6>
      </div>

      <div class="collapse" id="sluplusCollapse">
        <div class="card card-body">
          <p>
            I wrote this application as part of my Foundations of Rhetoric class my Sophomore year. My professor, Dr. Nathaniel Rivers, assigned us a project to map a part of the world in an interesting way. I created SLU+, an augmented reality app of Saint Louis University's campus. I used the <a href="https://www.wikitude.com/">Wikitude SDK</a> to overlay markers on statues and historic buildings. Users can tap on the markers to learn more about each landmark.
            <br>
            <br>
            This project was my first experience with the field of Human-Computer Interaction. I observed a few friends using the app. I learned that people experience an altered physical world when looking through the lens of an AR app. It shapes where they walk and look, and as a result, it shapes where other people walk and look. AR systems are rhetorical devices that affect how people network with physical objects and other people. These networks among humans and non-human devices run deep, and they affect how we attend.
            <br>
            <br>
            Unfortunately, I do not have the code for the application on a Github repo because I was not very experienced with Git at the time of the project. Here is a demo video of it.
            <br>
            <br>
            <div class="video-container">
              <iframe width="560" height="315" src="https://www.youtube.com/embed/-GV1qeCi-tM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </div>
          </p>
        </div>
      </div>


    </div>
  </header>
</section>
